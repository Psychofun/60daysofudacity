{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section: Securing Federated Learning\n",
    "\n",
    "- Lesson 1: Trusted Aggregator\n",
    "- Lesson 2: Intro to Additive Secret Sharing\n",
    "- Lesson 3: Intro to Fixed Precision Encoding\n",
    "- Lesson 4: Secret Sharing + Fixed Precision in PySyft\n",
    "- Final Project: Federated Learning wtih Encrypted Gradient Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson: Federated Learning with a Trusted Aggregator\n",
    "\n",
    "In the last section, we learned how to train a model on a distributed dataset using Federated Learning. In particular, the last project aggregated gradients directly from one data owner to another. \n",
    "\n",
    "However, while in some cases it could be ideal to do this, what would be even better is to be able to choose a neutral third party to perform the aggregation.\n",
    "\n",
    "As it turns out, we can use the same tools we used previously to accomplish this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Federated Learning with a Trusted Aggregator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try this project here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "import torch as th\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0707 15:32:01.289453  8828 hook.py:97] Torch was already hooked... skipping hooking process\n"
     ]
    }
   ],
   "source": [
    "hook = sy.TorchHook(th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn,optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Toy Dataset\n",
    "data = th.tensor([[1.0,1.0],[3,1.0],[1,1.0],[0,1.0],[23.0,1.0],[6,1.0],[7,1.0],[15,1.0],[9.0,1.0]], requires_grad=True)\n",
    "\n",
    "\n",
    "target = th.tensor([[2.],[6.0], [2.0], [0],[46.0],[12.0],[14.0],[30.0],[18.0]], requires_grad=True)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 3 #number of workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "workers  =[sy.VirtualWorker(hook, id = \"w\"+ str(i)) for i in range(m)]\n",
    "chunk_size = data.shape[0]//m\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets[0]\n",
      "tensor([[1., 1.],\n",
      "        [3., 1.],\n",
      "        [1., 1.]], grad_fn=<SliceBackward>)\n",
      "tensor([[2.],\n",
      "        [6.],\n",
      "        [2.]], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "#make a mini-dataset, one per worker\n",
    "datasets = [ [\n",
    "              data[j*chunk_size : (j+1) * chunk_size  ] ,\n",
    "              target[j*chunk_size : (j+1) * chunk_size] \n",
    "             ]\n",
    "            \n",
    "             for  j in range(m)\n",
    "           ]\n",
    "\n",
    "print(\"Datasets[0]\", *datasets[0], sep= \"\\n\")\n",
    "\n",
    "#send datasets to workers\n",
    "for k in range(m):\n",
    "    \n",
    "    datasets[k][0] = datasets[k][0].send(workers[k])\n",
    "    \n",
    "    datasets[k][1] = datasets[k][1].send(workers[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from random import shuffle\n",
    "\n",
    "def train_secure_grads(m,datasets,workers, iterations=20):\n",
    "    \"\"\"\n",
    "    iterations: int\n",
    "    \n",
    "    m: int\n",
    "        number of models/workers\n",
    "        \n",
    "    datasets: list of lists of tensors\n",
    "        [ [data_1,targets_1],[data_2, targets_2], ...     ]\n",
    "    \n",
    "    workers: list of VirtualWorkers\n",
    "    \n",
    "    iterations: int \n",
    "        number of SGD steps to do.\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    # Create a model for each worker \n",
    "    models = [ nn.Linear(2,1) for _ in range(m)]\n",
    "    \n",
    "    \n",
    "    # Global model\n",
    "    global_model = nn.Linear(2,1)\n",
    "    \n",
    "    # Create optims \n",
    "    optims = []\n",
    "\n",
    "    for i,t in enumerate(datasets):\n",
    "        \n",
    "        _data,_target  = t[0],t[1]\n",
    "        \n",
    "        \n",
    "        # Data preparation\n",
    "        \n",
    "        # send model to the data\n",
    "        models[i] = models[i].send(_data.location)\n",
    "        \n",
    "        #create optimizer for model i \n",
    "        #learning rate >= 0.1, makess trainig diverge on most models with little data.\n",
    "        optim_i = optim.SGD(params=models[i].parameters(), lr=0.001)\n",
    "        optims.extend( [optim_i] )\n",
    "        \n",
    "        for _ in range(iterations):            \n",
    "            # do normal training\n",
    "            optims[i].zero_grad()\n",
    "            pred = models[i](_data)\n",
    "            loss = ((pred - _target)**2).sum()\n",
    "            loss.backward()\n",
    "            \n",
    "            optims[i].step()\n",
    "\n",
    "            \n",
    "            print(\"Loss: {} for model: {}\".format( loss.clone().get().item(), i ))\n",
    "        \n",
    "        print(\"Params {} for model: {}\".format(models[i].weight.clone().get() ,i))\n",
    "        print()\n",
    "    \n",
    "    \n",
    "    # Average models on selected worker\n",
    "    \n",
    "    #shuffle models. Select first to aggregate gradients\n",
    "    shuffle(models)\n",
    "    \n",
    "    #Trusted agregator\n",
    "    # Selected worker to aggregate gradients.\n",
    "    sel_model = models[0]\n",
    "    \n",
    "    #move_model = lambda x: x.move(sel_worker)\n",
    "\n",
    "    w,b = sel_model.weight.data ,sel_model.bias.data\n",
    "    \n",
    "    for model in models[1:]:\n",
    "        # Move model to selected worker\n",
    "        model.move(sel_model.location)\n",
    "        \n",
    "        w+= model.weight.data\n",
    "        b+=  model.bias.data\n",
    "    \n",
    "    w = w/m\n",
    "    b = b/m\n",
    "    \n",
    "    with th.no_grad():\n",
    "    \n",
    "        global_model.weight.set_(  w.get() \n",
    "                                  )\n",
    "        global_model.bias.set_(    b.get() \n",
    "                                  )\n",
    "    \n",
    "    print(\"Params for model global model: {}\".format(global_model.weight.clone()))\n",
    "\n",
    "        \n",
    "    return global_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 83.87223815917969 for model: 0\n",
      "Loss: 78.7196273803711 for model: 0\n",
      "Loss: 73.89097595214844 for model: 0\n",
      "Loss: 69.36589813232422 for model: 0\n",
      "Loss: 65.12527465820312 for model: 0\n",
      "Loss: 61.151206970214844 for model: 0\n",
      "Loss: 57.4268913269043 for model: 0\n",
      "Loss: 53.93661880493164 for model: 0\n",
      "Loss: 50.66564178466797 for model: 0\n",
      "Loss: 47.600162506103516 for model: 0\n",
      "Loss: 44.72722625732422 for model: 0\n",
      "Loss: 42.03472137451172 for model: 0\n",
      "Loss: 39.51127624511719 for model: 0\n",
      "Loss: 37.146263122558594 for model: 0\n",
      "Loss: 34.92969512939453 for model: 0\n",
      "Loss: 32.85222244262695 for model: 0\n",
      "Loss: 30.90509796142578 for model: 0\n",
      "Loss: 29.080101013183594 for model: 0\n",
      "Loss: 27.36956024169922 for model: 0\n",
      "Loss: 25.766250610351562 for model: 0\n",
      "Loss: 24.263437271118164 for model: 0\n",
      "Loss: 22.854782104492188 for model: 0\n",
      "Loss: 21.534360885620117 for model: 0\n",
      "Loss: 20.29662322998047 for model: 0\n",
      "Loss: 19.136354446411133 for model: 0\n",
      "Loss: 18.04869270324707 for model: 0\n",
      "Loss: 17.029048919677734 for model: 0\n",
      "Loss: 16.073152542114258 for model: 0\n",
      "Loss: 15.176992416381836 for model: 0\n",
      "Loss: 14.336804389953613 for model: 0\n",
      "Loss: 13.549067497253418 for model: 0\n",
      "Loss: 12.810474395751953 for model: 0\n",
      "Loss: 12.117938041687012 for model: 0\n",
      "Loss: 11.468560218811035 for model: 0\n",
      "Loss: 10.859622955322266 for model: 0\n",
      "Loss: 10.288580894470215 for model: 0\n",
      "Loss: 9.753047943115234 for model: 0\n",
      "Loss: 9.250794410705566 for model: 0\n",
      "Loss: 8.7797212600708 for model: 0\n",
      "Loss: 8.337868690490723 for model: 0\n",
      "Loss: 7.923403263092041 for model: 0\n",
      "Loss: 7.534591197967529 for model: 0\n",
      "Loss: 7.169827938079834 for model: 0\n",
      "Loss: 6.827596664428711 for model: 0\n",
      "Loss: 6.506480693817139 for model: 0\n",
      "Loss: 6.2051520347595215 for model: 0\n",
      "Loss: 5.922365665435791 for model: 0\n",
      "Loss: 5.656959533691406 for model: 0\n",
      "Loss: 5.407834529876709 for model: 0\n",
      "Loss: 5.173973083496094 for model: 0\n",
      "Params tensor([[0.8637, 0.6990]], requires_grad=True) for model: 0\n",
      "\n",
      "Loss: 3490.897216796875 for model: 1\n",
      "Loss: 64.56145477294922 for model: 1\n",
      "Loss: 1.2009973526000977 for model: 1\n",
      "Loss: 0.029237650334835052 for model: 1\n",
      "Loss: 0.007485059089958668 for model: 1\n",
      "Loss: 0.006999434903264046 for model: 1\n",
      "Loss: 0.0069083115085959435 for model: 1\n",
      "Loss: 0.0068252612836658955 for model: 1\n",
      "Loss: 0.006743369624018669 for model: 1\n",
      "Loss: 0.00666265282779932 for model: 1\n",
      "Loss: 0.006582623813301325 for model: 1\n",
      "Loss: 0.006503571756184101 for model: 1\n",
      "Loss: 0.006425662897527218 for model: 1\n",
      "Loss: 0.006348784081637859 for model: 1\n",
      "Loss: 0.006272495724260807 for model: 1\n",
      "Loss: 0.006197219714522362 for model: 1\n",
      "Loss: 0.006122973281890154 for model: 1\n",
      "Loss: 0.006049606017768383 for model: 1\n",
      "Loss: 0.00597698288038373 for model: 1\n",
      "Loss: 0.005905326921492815 for model: 1\n",
      "Loss: 0.005834642797708511 for model: 1\n",
      "Loss: 0.005764659959822893 for model: 1\n",
      "Loss: 0.005695275031030178 for model: 1\n",
      "Loss: 0.005627261009067297 for model: 1\n",
      "Loss: 0.005559664685279131 for model: 1\n",
      "Loss: 0.0054930648766458035 for model: 1\n",
      "Loss: 0.005427120719105005 for model: 1\n",
      "Loss: 0.005362088326364756 for model: 1\n",
      "Loss: 0.005297612398862839 for model: 1\n",
      "Loss: 0.005234175361692905 for model: 1\n",
      "Loss: 0.005171454511582851 for model: 1\n",
      "Loss: 0.005109419114887714 for model: 1\n",
      "Loss: 0.0050480118952691555 for model: 1\n",
      "Loss: 0.00498752947896719 for model: 1\n",
      "Loss: 0.004927793517708778 for model: 1\n",
      "Loss: 0.004868723452091217 for model: 1\n",
      "Loss: 0.004810330457985401 for model: 1\n",
      "Loss: 0.004752579145133495 for model: 1\n",
      "Loss: 0.004695634823292494 for model: 1\n",
      "Loss: 0.004639252554625273 for model: 1\n",
      "Loss: 0.004583651199936867 for model: 1\n",
      "Loss: 0.004528684541583061 for model: 1\n",
      "Loss: 0.0044744135811924934 for model: 1\n",
      "Loss: 0.004420740529894829 for model: 1\n",
      "Loss: 0.00436760950833559 for model: 1\n",
      "Loss: 0.00431538000702858 for model: 1\n",
      "Loss: 0.004263575188815594 for model: 1\n",
      "Loss: 0.0042124344035983086 for model: 1\n",
      "Loss: 0.004161876626312733 for model: 1\n",
      "Loss: 0.004112036433070898 for model: 1\n",
      "Params tensor([[ 2.0027, -0.2810]], requires_grad=True) for model: 1\n",
      "\n",
      "Loss: 1071.05810546875 for model: 2\n",
      "Loss: 83.60557556152344 for model: 2\n",
      "Loss: 6.655986785888672 for model: 2\n",
      "Loss: 0.6592020392417908 for model: 2\n",
      "Loss: 0.19156530499458313 for model: 2\n",
      "Loss: 0.15480183064937592 for model: 2\n",
      "Loss: 0.15161368250846863 for model: 2\n",
      "Loss: 0.15104269981384277 for model: 2\n",
      "Loss: 0.15067832171916962 for model: 2\n",
      "Loss: 0.15032890439033508 for model: 2\n",
      "Loss: 0.1499813348054886 for model: 2\n",
      "Loss: 0.14963580667972565 for model: 2\n",
      "Loss: 0.14929072558879852 for model: 2\n",
      "Loss: 0.14894555509090424 for model: 2\n",
      "Loss: 0.14860272407531738 for model: 2\n",
      "Loss: 0.1482604742050171 for model: 2\n",
      "Loss: 0.1479170024394989 for model: 2\n",
      "Loss: 0.14757639169692993 for model: 2\n",
      "Loss: 0.14723588526248932 for model: 2\n",
      "Loss: 0.1468968391418457 for model: 2\n",
      "Loss: 0.1465579867362976 for model: 2\n",
      "Loss: 0.14621922373771667 for model: 2\n",
      "Loss: 0.14588187634944916 for model: 2\n",
      "Loss: 0.1455460786819458 for model: 2\n",
      "Loss: 0.14520952105522156 for model: 2\n",
      "Loss: 0.1448741853237152 for model: 2\n",
      "Loss: 0.1445411741733551 for model: 2\n",
      "Loss: 0.144207164645195 for model: 2\n",
      "Loss: 0.14387434720993042 for model: 2\n",
      "Loss: 0.14354248344898224 for model: 2\n",
      "Loss: 0.1432114690542221 for model: 2\n",
      "Loss: 0.1428806185722351 for model: 2\n",
      "Loss: 0.14255118370056152 for model: 2\n",
      "Loss: 0.14222244918346405 for model: 2\n",
      "Loss: 0.1418946087360382 for model: 2\n",
      "Loss: 0.1415676474571228 for model: 2\n",
      "Loss: 0.14123974740505219 for model: 2\n",
      "Loss: 0.14091463387012482 for model: 2\n",
      "Loss: 0.1405896097421646 for model: 2\n",
      "Loss: 0.140265554189682 for model: 2\n",
      "Loss: 0.1399415135383606 for model: 2\n",
      "Loss: 0.13961872458457947 for model: 2\n",
      "Loss: 0.1392964869737625 for model: 2\n",
      "Loss: 0.13897499442100525 for model: 2\n",
      "Loss: 0.13865453004837036 for model: 2\n",
      "Loss: 0.13833536207675934 for model: 2\n",
      "Loss: 0.13801543414592743 for model: 2\n",
      "Loss: 0.13769637048244476 for model: 2\n",
      "Loss: 0.13738015294075012 for model: 2\n",
      "Loss: 0.13706238567829132 for model: 2\n",
      "Params tensor([[ 2.0598, -0.4581]], requires_grad=True) for model: 2\n",
      "\n",
      "Params for model global model: tensor([[ 1.6420, -0.0134]], grad_fn=<CloneBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Linear(in_features=2, out_features=1, bias=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_secure_grads(m = 3, datasets = datasets,workers = workers, iterations = 50  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson: Intro to Additive Secret Sharing\n",
    "\n",
    "While being able to have a trusted third party to perform the aggregation is certainly nice, in an ideal setting we wouldn't have to trust anyone at all. This is where Cryptography can provide an interesting alterantive. \n",
    "\n",
    "Specifically, we're going to be looking at a simple protocol for Secure Multi-Party Computation called Additive Secret Sharing. This protocol will allow multiple parties (of size 3 or more) to aggregate their gradients without the use of a trusted 3rd party to perform the aggregation. In other words, we can add 3 numbers together from 3 different people without anyone ever learning the inputs of any other actors.\n",
    "\n",
    "Let's start by considering the number 5, which we'll put into a varible x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we wanted to SHARE the ownership of this number between two people, Alice and Bob. We could split this number into two shares, 2, and 3, and give one to Alice and one to Bob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob_x_share = 2\n",
    "alice_x_share = 3\n",
    "\n",
    "decrypted_x = bob_x_share + alice_x_share\n",
    "decrypted_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that neither Bob nor Alice know the value of x. They only know the value of their own SHARE of x. Thus, the true value of X is hidden (i.e., encrypted). \n",
    "\n",
    "The truly amazing thing, however, is that Alice and Bob can still compute using this value! They can perform arithmetic over the hidden value! Let's say Bob and Alice wanted to multiply this value by 2! If each of them multiplied their respective share by 2, then the hidden number between them is also multiplied! Check it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob_x_share = 2 * 2\n",
    "alice_x_share = 3 * 2\n",
    "\n",
    "decrypted_x = bob_x_share + alice_x_share\n",
    "decrypted_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This even works for addition between two shared values!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encrypted \"5\"\n",
    "bob_x_share = 2\n",
    "alice_x_share = 3\n",
    "\n",
    "# encrypted \"7\"\n",
    "bob_y_share = 5\n",
    "alice_y_share = 2\n",
    "\n",
    "# encrypted 5 + 7\n",
    "bob_z_share = bob_x_share + bob_y_share\n",
    "alice_z_share = alice_x_share + alice_y_share\n",
    "\n",
    "decrypted_z = bob_z_share + alice_z_share\n",
    "decrypted_z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we just added two numbers together while they were still encrypted!!!\n",
    "\n",
    "One small tweak - notice that since all our numbers are positive, it's possible for each share to reveal a little bit of information about the hidden value, namely, it's always greater than the share. Thus, if Bob has a share \"3\" then he knows that the encrypted value is at least 3.\n",
    "\n",
    "This would be quite bad, but can be solved through a simple fix. Decryption happens by summing all the shares together MODULUS some constant. I.e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23740629843736686616461"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 5\n",
    "\n",
    "Q = 23740629843760239486723\n",
    "\n",
    "bob_x_share = 23552870267 # <- a random number\n",
    "alice_x_share = Q - bob_x_share + x\n",
    "alice_x_share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(bob_x_share + alice_x_share) % Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now, as you can see, both shares are wildly larger than the number being shared, meaning that individual shares no longer leak this inforation. However, all the properties we discussed earlier still hold! (addition, encryption, decryption, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Build Methods for Encrypt, Decrypt, and Add \n",
    "\n",
    "In this project, you must take the lessons we learned in the last section and write general methods for encrypt, decrypt, and add. Store shares for a variable in a tuple like so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_share = (2,5,7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though normally those shares would be distributed amongst several workers, you can store them in ordered tuples like this for now :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try this project here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson: Intro to Fixed Precision Encoding\n",
    "\n",
    "As you may remember, our goal is to aggregate gradients using this new Secret Sharing technique. However, the protocol we've just explored in the last section uses positive integers. However, our neural network weights are NOT integers. Instead, our weights are decimals (floating point numbers).\n",
    "\n",
    "Not a huge deal! We just need to use a fixed precision encoding, which lets us do computation over decimal numbers using integers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE=10\n",
    "PRECISION=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(x):\n",
    "    return int((x * (BASE ** PRECISION)) % Q)\n",
    "\n",
    "def decode(x):\n",
    "    return (x if x <= Q/2 else x - Q) / BASE**PRECISION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(35000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.8"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = encrypt(encode(5.5))\n",
    "y = encrypt(encode(2.3))\n",
    "z = add(x,y)\n",
    "decode(decrypt(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson: Secret Sharing + Fixed Precision in PySyft\n",
    "\n",
    "While writing things from scratch is certainly educational, PySyft makes a great deal of this much easier for us through its abstractions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob = bob.clear_objects()\n",
    "alice = alice.clear_objects()\n",
    "secure_worker = secure_worker.clear_objects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = th.tensor([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Secret Sharing Using PySyft\n",
    "\n",
    "We can share using the simple .share() method!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.share(bob, alice, secure_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{35498656553: tensor([  10235770278698899, 1401398179551373756, 2277280072169145491,\n",
       "          636965538565031298,  913795591610271305])}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob._objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and as you can see, Bob now has one of the shares of x! Furthermore, we can still call addition in this state, and PySyft will automatically perform the remote execution for us!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Wrapper)>[AdditiveSharingTensor]\n",
       "\t-> (Wrapper)>[PointerTensor | me:23637986557 -> bob:30254176063]\n",
       "\t-> (Wrapper)>[PointerTensor | me:18229131498 -> alice:75856222543]\n",
       "\t-> (Wrapper)>[PointerTensor | me:34301722959 -> secure_worker:75419815101]\n",
       "\t*crypto provider: me*"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2,  4,  6,  8, 10])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed Precision using PySyft\n",
    "\n",
    "We can also convert a tensor to fixed precision using .fix_precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = th.tensor([0.1,0.2,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.2000, 0.3000])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.fix_prec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([100, 200, 300])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.child.child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2000, 0.4000, 0.6000])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.float_prec()\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shared Fixed Precision\n",
    "\n",
    "And of course, we can combine the two!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = th.tensor([0.1, 0.2, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.fix_prec().share(bob, alice, secure_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2000, 0.4000, 0.6000])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.get().float_prec()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to make the point that people can see the model averages in the clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project: Federated Learning with Encrypted Gradient Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "privateai",
   "language": "python",
   "name": "privateai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
